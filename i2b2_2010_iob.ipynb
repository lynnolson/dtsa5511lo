{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86bcbe80-bc51-4f4f-a5b7-5d8f189ce583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import glob\n",
    "import html\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "082658dc-0ed8-45bf-b73c-8952e26c02ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1959c78c-0c79-45e4-9c29-ec5f3d4ec96a",
   "metadata": {},
   "source": [
    "The i2b2 challenges do not provide data in the IOB format.  In this notebook we convert them to that format so they can be fed into our models and do some cleanup of the data, for example only including docs with annotations and filling in any empty labels with 'O' (for outside.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b7f994-3deb-4a1b-b183-85f12d07b4a3",
   "metadata": {},
   "source": [
    "# Convert i2b2 2010 Data to IOB Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36604382-a88f-4771-941d-96a5174e7680",
   "metadata": {},
   "source": [
    "The code in this section is modified from the Medium article [Named Entity Recognition for Clinical Text](https://medium.com/atlas-research/ner-for-clinical-text-7c73caddd180).  It has been modified to work with the LLMs in the primary notebook. Also, it was constructed to handle the i2b2 2011 task (co-reference resolution).  Unfortunately, the formats are not the same but close.\n",
    "\n",
    "Interestingly, that article is not in fact about NER, it's just about getting the i2b2 data into IOB format!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f0c5bf61-bbc5-4cdf-80db-876bbeb5210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(rootdir, suffix):\n",
    "    files = []\n",
    "    for dirname, _, filenames in os.walk(rootdir):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(suffix):\n",
    "                files.append(os.path.join(dirname, filename))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2598e9da-5b8d-4fe6-9050-410f4ebe61f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_files = find_files('data/i2b2/2010/', '.con')\n",
    "txt_files = find_files('data/i2b2/2010/', '.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d437069b-ad3a-4a03-b197-bb7107b79b80",
   "metadata": {},
   "source": [
    "It looks like we have some files that have not been annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "eb65f048-8c3a-4994-89fb-2e7c9bb8c531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 693)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotation_files), len(txt_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09716c63-5a8d-4ba8-8439-356eb1a200c4",
   "metadata": {},
   "source": [
    "Only include those text files that have been annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "07cdc688-f7b8-4611-983a-ae6abe755509",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = lambda fn,suf: fn.split('/')[-1].replace(suf, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b9929f38-3dae-4a33-9b6c-037546223192",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_file_set = set([filename(fn, '.con') for fn in annotation_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3d35b717-154d-4c4f-86b7-4d9484297254",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filterd_txt_files = [fn for fn in txt_files if filename(fn, '.txt') in annotated_file_set]\n",
    "txt_files = filterd_txt_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a474bcf-5f24-43c5-bf7d-1a057202140b",
   "metadata": {},
   "source": [
    "Good - it looks like we have 426 annotated files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "874dcb88-3329-4459-b4cb-ae2fd5f34028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 426)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotation_files), len(txt_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106cf1c2-612e-4971-bdb6-54c63cb437e7",
   "metadata": {},
   "source": [
    "Reorder these so the ids match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "da4afeb0-cb75-42d4-a71c-d1141d1b87be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "afiles_by_id = {filename(fn, '.con'): fn for fn in annotation_files}\n",
    "tfiles_by_id = {filename(fn, '.txt'): fn for fn in txt_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "579f9982-bfb5-4099-9eb2-8b75aca0366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ids, annotation_files, txt_files = zip(*[(id_, afn, tfiles_by_id[id_]) for id_, afn in afiles_by_id.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcfecb0-7c04-4643-90f6-bf86e119ab47",
   "metadata": {},
   "source": [
    "What are the entity types and their frequency?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9539f1a1-0e1f-48fb-8fad-6af28058f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_type_ctr = Counter()\n",
    "for fn in annotation_files:\n",
    "    with open(fn) as f:\n",
    "        for l in f:\n",
    "            entity_type_ctr.update([l.rstrip().split('||')[-1].split('=')[-1].replace('\"', '')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "55b138ec-525e-470d-8176-db2da7816fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('problem', 19665), ('treatment', 14188), ('test', 13833)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_type_ctr.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9ea0a8b9-2e24-41f0-ac83-1f4637bb3eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    with open(path) as f:\n",
    "        content = f.read().splitlines()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3b180a70-d878-463e-9b4f-b61f5ed21a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build annotation and entry corpora\n",
    "annotation_corpus = [read_file(fn) for fn in annotation_files]\n",
    "txt_corpus = [read_file(fn) for fn in txt_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "003aca6f-e2d3-4962-b959-5041430e6bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries_cols = [\"docid\", \"row\", \"offset\", \"word\"]\n",
    "entries_df = pd.DataFrame(columns=entries_cols)\n",
    "\n",
    "annotations_cols = [\"docid\", \"NER_tag\", \"row\", \"offset\", \"length\"]\n",
    "annotations_df = pd.DataFrame(columns=annotations_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2743371a-9366-4cdd-a1ec-358e2f01a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df = pd.DataFrame(columns=annotations_cols)  # Reset df\n",
    "tmp_list = []  # Set up variable to hold row info\n",
    "\n",
    "for i, document in enumerate(annotation_corpus):\n",
    "    \n",
    "    for row in document:\n",
    "        text_info, type_info = row.split(\"||\")\n",
    "        \n",
    "        text = text_info.split('\"')[1]\n",
    "        \n",
    "        offset_start = text_info.split(' ')[-2]\n",
    "        offset_end = text_info.split(' ')[-1]\n",
    "        \n",
    "        line = offset_start.split(':')[0] # Given one sentence to line, \n",
    "                                          # line number will be the same for offset_start and offset_end\n",
    "        \n",
    "        word_offset_start = int(offset_start.split(':')[1])\n",
    "        word_offset_end = int(offset_end.split(':')[1])\n",
    "        length = word_offset_end-word_offset_start +1\n",
    "        \n",
    "        a_type = type_info.split('\"')[-2]\n",
    "        \n",
    "        # Split text into tokens with IOB tags\n",
    "        first = True  # Set up flag to id start of text\n",
    "        BIO_tag = \"B-\"\n",
    "        if length > 1:  # Isolate text with multiple tokens \n",
    "            for offset in range(word_offset_start, word_offset_end+1):\n",
    "                if first:\n",
    "                    tag_label = BIO_tag + a_type # Set tag for first word to start with B-\n",
    "                    first = False  # Change flag\n",
    "                else:\n",
    "                    tag_label = tag_label.replace(\"B-\", \"I-\")\n",
    "                tmp_list.append([a_ids[i], tag_label, line, offset, 1])                \n",
    "        else:\n",
    "            tmp_list.append([a_ids[i], BIO_tag + a_type, line, word_offset_start, length])\n",
    "        \n",
    "annotations_df = pd.DataFrame(tmp_list, columns=annotations_cols)\n",
    "annotations_df = annotations_df.drop(columns=[\"length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4be98ba6-cb64-49c5-bf3a-a8ab45bae59b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>NER_tag</th>\n",
       "      <th>row</th>\n",
       "      <th>offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>405507617</td>\n",
       "      <td>B-problem</td>\n",
       "      <td>61</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>405507617</td>\n",
       "      <td>I-problem</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>405507617</td>\n",
       "      <td>I-problem</td>\n",
       "      <td>61</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>405507617</td>\n",
       "      <td>I-problem</td>\n",
       "      <td>61</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>405507617</td>\n",
       "      <td>I-problem</td>\n",
       "      <td>61</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       docid    NER_tag  row  offset\n",
       "0  405507617  B-problem   61      18\n",
       "1  405507617  I-problem   61      19\n",
       "2  405507617  I-problem   61      20\n",
       "3  405507617  I-problem   61      21\n",
       "4  405507617  I-problem   61      22"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "84fbd42b-b8a0-45c7-8246-183f01876ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47686 named entities\n"
     ]
    }
   ],
   "source": [
    "entries_df = pd.DataFrame(columns=entries_cols)  # Reset df\n",
    "tmp_list = []\n",
    "\n",
    "for doc_i, document in enumerate(txt_corpus):\n",
    "    for row_i, row in enumerate(document):\n",
    "        row_split = row.split(\" \")\n",
    "        for word_i, word in enumerate(row_split):\n",
    "            word = word.replace(\"\\t\", \"\")\n",
    "            word_id = a_ids[doc_i]\n",
    "            word_row = row_i+1  # 1-based indexing \n",
    "            word_offset = word_i # 0-based indexing\n",
    "            if len(word) > 0 and \"|\" not in word:\n",
    "                tmp_list.append([word_id, word_row, word_offset, word])\n",
    "\n",
    "entries_df = pd.DataFrame(tmp_list, columns=entries_cols)\n",
    "\n",
    "ner_counter = [1 for i in annotations_df[\"NER_tag\"] if \"B-\" in i]\n",
    "print(len(ner_counter), \"named entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8751b02e-1bcb-43b0-b04a-3a9e3aca312f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>row</th>\n",
       "      <th>offset</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>405507617</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>405507617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>405507617</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>FIH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>405507617</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2887168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>405507617</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>132052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>405507617</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>543394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416776</th>\n",
       "      <td>0390</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>Dr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416777</th>\n",
       "      <td>0390</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>Thorebreutz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416778</th>\n",
       "      <td>0390</td>\n",
       "      <td>118</td>\n",
       "      <td>2</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416779</th>\n",
       "      <td>0390</td>\n",
       "      <td>118</td>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416780</th>\n",
       "      <td>0390</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416781 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            docid  row  offset         word\n",
       "0       405507617    1       0    405507617\n",
       "1       405507617    2       0          FIH\n",
       "2       405507617    3       0      2887168\n",
       "3       405507617    4       0       132052\n",
       "4       405507617    5       0       543394\n",
       "...           ...  ...     ...          ...\n",
       "416776       0390  118       0          Dr.\n",
       "416777       0390  118       1  Thorebreutz\n",
       "416778       0390  118       2            ,\n",
       "416779       0390  118       3            E\n",
       "416780       0390  118       4            2\n",
       "\n",
       "[416781 rows x 4 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "79c21c5e-e026-49c8-896d-92675b4f2a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing data:\n",
      " docid      False\n",
      "row        False\n",
      "offset     False\n",
      "word       False\n",
      "NER_tag     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Ensure correct dtypes\n",
    "\n",
    "annotations_df[['row', 'offset']] = annotations_df[['row', 'offset']].apply(pd.to_numeric)\n",
    "annotations_df['NER_tag'] = annotations_df[\"NER_tag\"].astype(str)\n",
    "entries_df[['row', 'offset']] = entries_df[['row', 'offset']].apply(pd.to_numeric)\n",
    "entries_df[\"word\"] = entries_df[\"word\"].astype(str)\n",
    "\n",
    "result_df = pd.merge(entries_df, annotations_df, how=\"left\", on=['docid', 'row', 'offset'])\n",
    "\n",
    "# Check for NaNs (should be only in NER_tag, where NaNs will be replaced with \"O\" (outside))\n",
    "print(\"Columns with missing data:\\n\", result_df.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dbf57dec-1f82-4fc1-be71-c603fbee8584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47678 named entities and 416789 tokens\n"
     ]
    }
   ],
   "source": [
    "result_df = result_df.fillna(\"O\")\n",
    "result_df = result_df.drop(columns=[\"row\", \"offset\"])\n",
    "\n",
    "ner_counter = [1 for i in result_df[\"NER_tag\"] if \"B-\" in i]\n",
    "print(len(ner_counter), \"named entities and\", result_df.shape[0], \"tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "39625e2d-c2af-4546-bafe-3a6578fe177a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>word</th>\n",
       "      <th>NER_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>405507617</td>\n",
       "      <td>405507617</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>405507617</td>\n",
       "      <td>FIH</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>405507617</td>\n",
       "      <td>2887168</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>405507617</td>\n",
       "      <td>132052</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>405507617</td>\n",
       "      <td>543394</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>405507617</td>\n",
       "      <td>11/12/2002</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>405507617</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>405507617</td>\n",
       "      <td>AM</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>405507617</td>\n",
       "      <td>Discharge</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>405507617</td>\n",
       "      <td>Summary</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       docid        word NER_tag\n",
       "0  405507617   405507617       O\n",
       "1  405507617         FIH       O\n",
       "2  405507617     2887168       O\n",
       "3  405507617      132052       O\n",
       "4  405507617      543394       O\n",
       "5  405507617  11/12/2002       O\n",
       "6  405507617    12:00:00       O\n",
       "7  405507617          AM       O\n",
       "8  405507617   Discharge       O\n",
       "9  405507617     Summary       O"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a4224a03-350a-40ce-af61-6b3b09454d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_docs = result_df.docid.nunique()\n",
    "n_words = result_df.word.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a17d20b6-7817-438e-a547-fd1f221e1901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 416789, 978)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_docs, n_words, int(np.round(n_words/n_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ba6131fa-1025-4982-bdf3-c914d6975690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NER_tag\n",
       "O              317223\n",
       "I-problem       27936\n",
       "B-problem       19663\n",
       "B-treatment     14187\n",
       "B-test          13828\n",
       "I-treatment     12054\n",
       "I-test          11898\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies = result_df.NER_tag.value_counts()\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "72aaecee-cb3c-480a-90c4-6048f796dcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('problem', 47599), ('treatment', 26241), ('test', 25726)]\n"
     ]
    }
   ],
   "source": [
    "tags = {}\n",
    "for tag, count in zip(frequencies.index, frequencies):\n",
    "    if tag != \"O\":\n",
    "        if tag[2:] not in tags.keys():\n",
    "            tags[tag[2:]] = count\n",
    "        else:\n",
    "            tags[tag[2:]] += count\n",
    "    continue\n",
    "\n",
    "print(sorted(tags.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "09fc3348-358e-4b05-a3e7-3e8f6a49972d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing data:\n",
      " docid      False\n",
      "word       False\n",
      "NER_tag    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns with missing data:\\n\", result_df.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "93d75950-559d-40d4-a6df-03f58643986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_pickle('data/i2b2/2010/i2b2_dataset_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
